{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment - 5\n",
        "### Aim: To study and implement bagging using Random Forests.\n",
        "### Abstract:\n",
        "The aim of this experiment is to investigate and implement the bagging technique using random forests and evaluate its performance in comparison to individual decision trees. Bagging, short for bootstrap aggregating, is an ensemble learning method that combines multiple models trained on different subsets of the dataset to improve predictive accuracy and reduce overfitting. Random forests, which employ bagging on decision trees, further enhance the performance by introducing randomization in the feature selection process. In this experiment, we will implement and evaluate the bagging technique using random forests on a selected dataset to assess its effectiveness in enhancing predictive accuracy."
      ],
      "metadata": {
        "id": "EqI5rpwTLZl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procedure:"
      ],
      "metadata": {
        "id": "JfNnescjONcu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dLkC_RLhLSVQ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Dataset Selection"
      ],
      "metadata": {
        "id": "p1IEa_hFOjKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "yerWFoTyOc3T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Data Preprocessing (Not required for the Iris dataset)\n"
      ],
      "metadata": {
        "id": "I25Kl7T9OxeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Implementation of Bagging using Random Forests"
      ],
      "metadata": {
        "id": "kUa0AetaO1Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the random forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=10)"
      ],
      "metadata": {
        "id": "9RRAx9aWOsfD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Experimental Setup"
      ],
      "metadata": {
        "id": "_YscIzOdPGMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "yuW8XrM0PDVw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Performance Evaluation Metrics (Accuracy in this case)\n"
      ],
      "metadata": {
        "id": "MrW6aV_cPOnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Comparison and Analysis\n"
      ],
      "metadata": {
        "id": "hx_7yDH8PWfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the random forest classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the labels for the testing set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculating the accuracy of the random forest classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Random Forest:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyODrdhAPQvH",
        "outputId": "06539b01-fcfb-43f2-e398-30053f225594"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Random Forest: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Training individual decision trees\n",
        "decision_trees = []\n",
        "for i in range(10):\n",
        "    decision_tree = DecisionTreeClassifier()\n",
        "    decision_tree.fit(X_train, y_train)\n",
        "    decision_trees.append(decision_tree)\n",
        "\n",
        "# Predicting the labels using individual decision trees\n",
        "y_preds_individual = [tree.predict(X_test) for tree in decision_trees]\n",
        "\n",
        "# Combining the predictions of individual decision trees\n",
        "y_pred_bagged = np.round(np.mean(y_preds_individual, axis=0))\n",
        "\n",
        "# Calculating the accuracy of individual decision trees\n",
        "accuracy_individual = accuracy_score(y_test, y_pred_bagged)\n",
        "print(\"Accuracy of Individual Decision Trees:\", accuracy_individual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgG8VD0dPpvv",
        "outputId": "7908cc9f-cc62-4a6c-9b03-b6c54df4bf4a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Individual Decision Trees: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion: \n",
        "By conducting this experiment, we gained insights into the performance of bagging using random forests and understood its potential benefits in improving predictive accuracy compared to individual decision trees."
      ],
      "metadata": {
        "id": "jbPa6RXfN3Ov"
      }
    }
  ]
}